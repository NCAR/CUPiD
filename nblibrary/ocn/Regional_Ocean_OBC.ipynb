{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47505ca2",
   "metadata": {},
   "source": [
    "## Regional Ocean: Checking Open Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fa78b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import regional_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddeb9e",
   "metadata": {
    "tags": [
     "parameters",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "case_name = \"\"  # \"/glade/campaign/cgd/oce/projects/CROCODILE/workshops/2025/Diagnostics/CESM_Output/\"\n",
    "CESM_output_dir = \"\"  # \"CROCODILE_tutorial_nwa12_MARBL\"\n",
    "\n",
    "# As regional domains vary so much in purpose, simulation length, and extent, we don't want to assume a minimum duration\n",
    "## Thus, we ignore start and end dates and simply reduce/output over the whole time frame for all of the examples given.\n",
    "start_date = None  # \"0001-01-01\"\n",
    "end_date = None  # \"0101-01-01\n",
    "\n",
    "save_figs = False\n",
    "fig_output_dir = None\n",
    "\n",
    "lc_kwargs = {}\n",
    "serial = False\n",
    "\n",
    "## Notebook Specific Arguments\n",
    "# case_root is automatically populated in a CESM CUPiD workflow\n",
    "# If case_root is specified, and mom6_input_dir is not, INPUTDIR will be inferred from user_nl_mom in case_root\n",
    "# If mom6_input_dir is specified, case_root will be ignored\n",
    "# NOTE: If case_root and mom6_input_dir are both None, the notebook will not run\n",
    "# If obc_file_str is unspecified, defaults to \"forcing_obc_segment_00*.nc\"\n",
    "case_root = None\n",
    "mom6_input_dir = None  # \"/glade/campaign/cgd/oce/projects/CROCODILE/workshops/2025/Diagnostics/Input_Dir/CROCODILE_tutorial_nwa12_MARBL_ocnice\"\n",
    "obc_file_str = None  # Pattern for OBC file names: \"forcing_obc_segment_00*.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05209e7b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "OUTDIR = f\"{CESM_output_dir}/{case_name}/ocn/hist/\"\n",
    "print(\"Output directory is:\", OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ea24e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "case_output_dir = os.path.join(CESM_output_dir, case_name, \"ocn\", \"hist\")\n",
    "\n",
    "# Xarray time decoding things\n",
    "time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "\n",
    "## Static data includes hgrid, vgrid, bathymetry, land/sea mask\n",
    "static_data = xr.open_mfdataset(\n",
    "    os.path.join(case_output_dir, f\"*static.nc\"),\n",
    "    decode_timedelta=True,\n",
    "    decode_times=time_coder,\n",
    ")\n",
    "\n",
    "## Surface Data\n",
    "sfc_data = xr.open_mfdataset(\n",
    "    os.path.join(case_output_dir, f\"*sfc*.nc\"),\n",
    "    decode_timedelta=True,\n",
    "    decode_times=time_coder,\n",
    ")\n",
    "\n",
    "# ## Monthly Domain Data\n",
    "# monthly_data = xr.open_mfdataset(\n",
    "#     os.path.join(case_output_dir, f\"*z*.nc\"),\n",
    "#     decode_timedelta=True,\n",
    "#     decode_times=time_coder,\n",
    "# )\n",
    "\n",
    "# ## Native Monthly Domain Data\n",
    "# native_data = xr.open_mfdataset(\n",
    "#     os.path.join(case_output_dir, f\"*native*.nc\"),\n",
    "#     decode_timedelta=True,\n",
    "#     decode_times=time_coder,\n",
    "# )\n",
    "\n",
    "## Image/Gif Output Directory\n",
    "if fig_output_dir is None:\n",
    "    image_output_dir = os.path.join(\n",
    "        \"/glade/derecho/scratch/\",\n",
    "        os.environ[\"USER\"],\n",
    "        \"archive\",\n",
    "        case_name,\n",
    "        \"ocn\",\n",
    "        \"cupid_images\",\n",
    "    )\n",
    "else:\n",
    "    image_output_dir = os.path.join(fig_output_dir, case_name, \"ocn\", \"cupid_images\")\n",
    "if not os.path.exists(image_output_dir):\n",
    "    os.makedirs(image_output_dir)\n",
    "print(\"Image output directory is:\", image_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe702b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply time boundaries\n",
    "if len(start_date) > 0 and len(end_date) > 0:\n",
    "    import cftime\n",
    "\n",
    "    calendar = sfc_data.time.encoding.get(\"calendar\", \"standard\")\n",
    "\n",
    "    calendar_map = {\n",
    "        \"gregorian\": cftime.DatetimeProlepticGregorian,\n",
    "        \"noleap\": cftime.DatetimeNoLeap,\n",
    "    }\n",
    "\n",
    "    CFTime = calendar_map.get(calendar, cftime.DatetimeGregorian)\n",
    "    y, m, d = [int(i) for i in start_date.split(\"-\")]\n",
    "    start_date_time = CFTime(y, m, d)\n",
    "    y, m, d = [int(i) for i in end_date.split(\"-\")]\n",
    "    end_date_time = CFTime(y, m, d)\n",
    "\n",
    "    sfc_data = sfc_data.sel(time=slice(start_date_time, end_date_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ae3db",
   "metadata": {},
   "source": [
    "## Accessing and Processing Open Boundary Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d565157d",
   "metadata": {},
   "source": [
    "#### Regional MOM6 Input Directory\n",
    "\n",
    "Regional MOM6 configurations use a separate input directory containing the data for the initial state, tides, and boundary conditions. This notebook needs to access the boundary conditions. There are a couple options here:\n",
    "\n",
    "We instead look for the input directory path in two locations in the `case_root` directory:\n",
    "- `user_nl_mom`\n",
    "- `Buildconf/momconf/MOM_input`\n",
    "  \n",
    "In both files, the input directory path should have the name `INPUTDIR`. If this path cannot be found, the rest of this notebook will fail to run, but the user can manually set the input directory path below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d7e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = None\n",
    "\n",
    "for file in [\"user_nl_mom\", \"BuildConf/momconf/MOM_input\"]:\n",
    "    filepath = Path(os.path.join(case_root, file))\n",
    "\n",
    "    if filepath.is_file():\n",
    "        with open(filepath, \"r\") as f:\n",
    "            for line in f:\n",
    "                if line.strip().startswith(\"INPUTDIR\"):\n",
    "                    key, value = line.split(\"=\", 1)\n",
    "\n",
    "                    input_dir = value.strip()\n",
    "                    break\n",
    "\n",
    "    if Path(input_dir).is_dir():\n",
    "        print(f\"Found INPUTDIR in {file}\")\n",
    "        break\n",
    "\n",
    "# Override if autmatic method doesn't work:\n",
    "# input_dir = user/specified/path\n",
    "\n",
    "if input_dir is None:\n",
    "    print(\n",
    "        \"INPUTDIR not found. Try Setting it manually in the `Regional_Ocean_OBC` notebook.\"\n",
    "    )\n",
    "    raise FileNotFoundError(\n",
    "        \"INPUTDIR not found. Try Setting it manually in the `Regional_Ocean_OBC` notebook.\"\n",
    "    )\n",
    "\n",
    "print(f\"INPUTDIR: {input_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98edf2a",
   "metadata": {},
   "source": [
    "#### Check for Boundary Conditions, Verify Horizontal Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ed047",
   "metadata": {},
   "source": [
    "The input directory should contain a few different files:\n",
    "- `init*`: initial fields\n",
    "- `ocean_hgrid.nc`, `ocean_topo.nc`, `vgrid*.nc`: grids and bathymetry\n",
    "- `tu*` and `tz*`: tidal forcing\n",
    "  \n",
    "What we care about:\n",
    "- **`forcing_obc_segment*.nc`**: open boundary conditions to force the model\n",
    "\n",
    "The numbers at the end of the file each correspond to a different edge of the domain. \n",
    "- 001: south\n",
    "- 002: north\n",
    "- 003: west\n",
    "- 004: east"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_conds = glob.glob(os.path.join(input_dir, \"forcing_obc_segment_*.nc\"))\n",
    "print(f\"Found {len(boundary_conds)} OBC files:\", boundary_conds)\n",
    "\n",
    "if len(boundary_conds) == 0:\n",
    "    raise FileNotFoundError(f\"No boundary condition files found at {input_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a54d4d",
   "metadata": {},
   "source": [
    "#### Opening and Checking Open Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_num_to_dir = {\n",
    "    \"001\": \"south\",\n",
    "    \"002\": \"north\",\n",
    "    \"003\": \"west\",\n",
    "    \"004\": \"east\",\n",
    "}\n",
    "segment_dir_to_num = {v: k for k, v in segment_num_to_dir.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe91c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_boundaries = []\n",
    "temp_time_slice = slice(0, 5)\n",
    "\n",
    "for boundary_file in boundary_conds:\n",
    "\n",
    "    boundary = xr.open_mfdataset(boundary_file)\n",
    "\n",
    "    # Temp time slice\n",
    "    boundary = boundary.isel(time=temp_time_slice)\n",
    "\n",
    "    code = (boundary_file.split(\"_\")[-1]).split(\".\")[0]\n",
    "    bound = segment_num_to_dir[code]\n",
    "\n",
    "    # Variables on the U/V grid (corners)\n",
    "    uv_vars = [f\"u_segment_{code}\", f\"v_segment_{code}\"]\n",
    "\n",
    "    # Variables on the T grid (cell center)\n",
    "    tracer_vars = [\n",
    "        f\"salt_segment_{code}\",\n",
    "        f\"temp_segment_{code}\",\n",
    "        f\"eta_segment_{code}\",\n",
    "    ]\n",
    "\n",
    "    # Create separate datasets for each grid type\n",
    "    boundary_uv = boundary[uv_vars]\n",
    "    boundary_t = boundary[tracer_vars]\n",
    "\n",
    "    # Rename coordinates for both datasets\n",
    "    boundary_uv = boundary_uv.rename(\n",
    "        {\n",
    "            f\"ny_segment_{code}\": \"yq\",\n",
    "            f\"nx_segment_{code}\": \"xq\",\n",
    "            f\"lon_segment_{code}\": \"longitude_q\",\n",
    "            f\"lat_segment_{code}\": \"latitude_q\",\n",
    "        }\n",
    "    )\n",
    "    boundary_t = boundary_t.rename(\n",
    "        {\n",
    "            f\"ny_segment_{code}\": \"yh\",\n",
    "            f\"nx_segment_{code}\": \"xh\",\n",
    "            f\"lon_segment_{code}\": \"longitude_h\",\n",
    "            f\"lat_segment_{code}\": \"latitude_h\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Drop variables and handle squeeze for both\n",
    "    boundary_uv = boundary_uv.drop_vars([\"nxp\", \"nyp\"])\n",
    "    boundary_t = boundary_t.drop_vars([\"nxp\", \"nyp\"])\n",
    "\n",
    "    if bound in [\"north\", \"south\"]:\n",
    "        # Slicing for a C-grid\n",
    "        boundary_uv = boundary_uv.isel(xq=slice(0, None, 2))\n",
    "        boundary_t = boundary_t.isel(xh=slice(1, None, 2))\n",
    "\n",
    "        # Assign new coordinates\n",
    "        boundary_uv = boundary_uv.assign_coords(\n",
    "            xq=(\"xq\", boundary_uv[\"longitude_q\"].values)\n",
    "        )\n",
    "        boundary_t = boundary_t.assign_coords(\n",
    "            xh=(\"xh\", boundary_t[\"longitude_h\"].values)\n",
    "        )\n",
    "\n",
    "        # boundary_uv = boundary_uv.squeeze('yq', drop = True)\n",
    "        # boundary_t = boundary_t.squeeze('yh', drop = True)\n",
    "    else:\n",
    "        # Slicing for a C-grid\n",
    "        boundary_uv = boundary_uv.isel(yq=slice(0, None, 2))\n",
    "        boundary_t = boundary_t.isel(yh=slice(1, None, 2))\n",
    "\n",
    "        # Assign new coordinates\n",
    "        boundary_uv = boundary_uv.assign_coords(\n",
    "            yq=(\"yq\", boundary_uv[\"latitude_q\"].values)\n",
    "        )\n",
    "        boundary_t = boundary_t.assign_coords(\n",
    "            yh=(\"yh\", boundary_t[\"latitude_h\"].values)\n",
    "        )\n",
    "\n",
    "        # boundary_uv = boundary_uv.squeeze('xq', drop = True)\n",
    "        # boundary_t = boundary_t.squeeze('xh', drop = True)\n",
    "\n",
    "    # Combine the processed datasets\n",
    "    boundary = xr.merge([boundary_uv, boundary_t])\n",
    "\n",
    "    # Remove longitude and latitude variables from the datasets\n",
    "    for coord in [\"longitude_q\", \"latitude_q\"]:\n",
    "        if coord in boundary:\n",
    "            boundary = boundary.drop_vars(coord)\n",
    "    for coord in [\"longitude_h\", \"latitude_h\"]:\n",
    "        if coord in boundary:\n",
    "            boundary = boundary.drop_vars(coord)\n",
    "\n",
    "    # Dumb check to make sure OBCs are on the same grid as model output\n",
    "    model_xh = static_data[\"xh\"]\n",
    "    model_yh = static_data[\"yh\"]\n",
    "    model_xq = static_data[\"xq\"]\n",
    "    model_yq = static_data[\"yq\"]\n",
    "\n",
    "    # if boundary['xh'].size > 1: assert np.allclose(boundary['xh'].values, model_xh.values, atol=1e-6), f\"Boundary {bound} x-coordinates do not match model grid\"\n",
    "    # if boundary['yh'].size > 1: assert np.allclose(boundary['yh'].values, model_yh.values, atol=1e-6), f\"Boundary {bound} y-coordinates do not match model grid\"\n",
    "    # if boundary['xq'].size > 1: assert np.allclose(boundary['xq'].values, model_xq.values, atol=1e-6), f\"Boundary {bound} corner x-coordinates do not match model grid\"\n",
    "    # if boundary['yq'].size > 1: assert np.allclose(boundary['yq'].values, model_yq.values, atol=1e-6), f\"Boundary {bound} corner y-coordinates do not match model grid\"\n",
    "\n",
    "    z_map = [\n",
    "        f\"nz_segment_{code}_u\",\n",
    "        f\"nz_segment_{code}_v\",\n",
    "        f\"nz_segment_{code}_temp\",\n",
    "        f\"nz_segment_{code}_salt\",\n",
    "    ]\n",
    "    new_boundary = {}\n",
    "    for var in boundary.data_vars:\n",
    "        da = boundary[var]\n",
    "        da.load()\n",
    "\n",
    "        zdim = [str(d) for d in da.dims if str(d) in z_map]\n",
    "        if len(zdim) > 0:\n",
    "            da = da.rename({zdim[0]: \"z_l\"})\n",
    "        new_boundary[var.split(\"_\")[0]] = da\n",
    "\n",
    "    new_boundary = xr.Dataset(new_boundary).expand_dims(boundary=[bound])\n",
    "    list_boundaries.append(new_boundary)\n",
    "\n",
    "# boundaries = xr.concat(list_boundaries, dim = 'boundary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_boundaries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e433c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a487b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cupid-analysis]",
   "language": "python",
   "name": "conda-env-cupid-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
