{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bde298-3456-40dd-8011-c61df95f5f77",
   "metadata": {},
   "source": [
    "# Compare crop yields to observations\n",
    "\n",
    "- Uses raw annual CTSM outputs (NOT timeseries files).\n",
    "\n",
    "Notebook created by Sam Rabin (samrabin@ucar.edu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750da831-1c5c-4b41-947e-a9e57a62a820",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from dask.distributed import Client, wait\n",
    "import convert_pft1d_to_sparse\n",
    "import importlib\n",
    "\n",
    "# Plotting utils\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "ctsm_python_gallery_path = (\n",
    "    \"/glade/work/samrabin/cupid_crops/externals/ctsm_python_gallery\"\n",
    ")\n",
    "sys.path.append(ctsm_python_gallery_path)\n",
    "import ctsm_py.utils\n",
    "import ctsm_py.crop_secondary_variables as c2o\n",
    "import ctsm_py.mark_crops_invalid as mci\n",
    "\n",
    "# Start a local Dask cluster using all available cores\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bff86d-21fe-41a6-a998-76cb6a57606f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69c65d-fe0e-435f-b448-7ad69233f97a",
   "metadata": {},
   "source": [
    "### 1.1 Parameters modifiable in config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f2d17-c653-4ad1-9dc3-c49bf836ceb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Where land output is stored\n",
    "CESM_output_dir = os.path.join(\n",
    "    os.path.sep,\n",
    "    \"glade\",\n",
    "    \"work\",\n",
    "    \"samrabin\",\n",
    "    \"clm6_crop_reparam_outputs\",\n",
    ")\n",
    "\n",
    "# Full casenames that are present in CESM_output_dir and in individual filenames\n",
    "case_name_list = [\n",
    "    \"ctsm53019_f09_BNF_hist\",\n",
    "    \"clm6_crop_032\",\n",
    "    \"clm6_crop_032_nomaxlaitrig\",\n",
    "]\n",
    "\n",
    "clm_file_h = \".h0.\"\n",
    "\n",
    "# The actual netCDF timesteps, not the names of the files\n",
    "start_year = 1961\n",
    "end_year = 2023\n",
    "\n",
    "cfts_to_include = [\n",
    "    \"temperate_corn\",\n",
    "    \"tropical_corn\",\n",
    "    \"cotton\",\n",
    "    \"rice\",\n",
    "    \"temperate_soybean\",\n",
    "    \"tropical_soybean\",\n",
    "    \"sugarcane\",\n",
    "    \"spring_wheat\",\n",
    "    \"irrigated_temperate_corn\",\n",
    "    \"irrigated_tropical_corn\",\n",
    "    \"irrigated_cotton\",\n",
    "    \"irrigated_rice\",\n",
    "    \"irrigated_temperate_soybean\",\n",
    "    \"irrigated_tropical_soybean\",\n",
    "    \"irrigated_sugarcane\",\n",
    "    \"irrigated_spring_wheat\",\n",
    "]\n",
    "\n",
    "crops_to_include = [\n",
    "    \"corn\",\n",
    "    \"cotton\",\n",
    "    \"rice\",\n",
    "    \"soybean\",\n",
    "    \"sugarcane\",\n",
    "    \"wheat\",\n",
    "]\n",
    "fao_to_clm_dict = {\n",
    "    \"Maize\": \"corn\",\n",
    "    \"Rice\": \"rice\",\n",
    "    \"Seed cotton, unginned\": \"cotton\",\n",
    "    \"Soya beans\": \"soybean\",\n",
    "    \"Sugar cane\": \"sugarcane\",\n",
    "    \"Wheat\": \"wheat\",\n",
    "}\n",
    "\n",
    "dev_mode = True\n",
    "verbose = True\n",
    "\n",
    "obs_data_dir = os.path.join(\n",
    "    os.sep + \"glade\",\n",
    "    \"campaign\",\n",
    "    \"cesm\",\n",
    "    \"development\",\n",
    "    \"cross-wg\",\n",
    "    \"diagnostic_framework\",\n",
    "    \"CUPiD_obs_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4028f-3211-4454-956e-7b35be7f239b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1.2 Other settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014712f-d094-4dae-b583-740bf7a9789c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set up directory for any scratch output\n",
    "if \"SCRATCH\" in os.environ:\n",
    "    cupid_temp = os.path.join(os.environ[\"SCRATCH\"], \"CUPiD_scratch\")\n",
    "    os.makedirs(cupid_temp, exist_ok=True)\n",
    "else:\n",
    "    cupid_temp = \".\"\n",
    "\n",
    "N_PFTS = 78\n",
    "\n",
    "short_names = [case.split(\".\")[-1] for case in case_name_list]\n",
    "\n",
    "if start_year > end_year:\n",
    "    raise RuntimeError(f\"start_year ({start_year}) > end_year ({end_year})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f59509-0094-466e-bded-0929077936e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2. Import case data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5f640-06c4-4904-8813-b749263e1d8c",
   "metadata": {},
   "source": [
    "### 2.1 Set up classes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42654bef-46e3-4c55-82c4-467c6d05ab55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "importlib.reload(c2o)\n",
    "\n",
    "\n",
    "class Cft:\n",
    "    def __init__(self, name, cft_num):\n",
    "        self.name = name\n",
    "\n",
    "        # 1-indexed in the FORTRAN style\n",
    "        self.cft_num = cft_num\n",
    "        self.pft_num = None  # Need to know max cft_num\n",
    "\n",
    "        # 0-indexed in the Python style\n",
    "        self.pft_ind = None  # Need to know pft_num\n",
    "        self.where = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\".join(\n",
    "            [\n",
    "                self.name + \":\",\n",
    "                f\"   cft_num: {self.cft_num}\",\n",
    "                f\"   pft_num: {self.pft_num}\",\n",
    "                f\"   pft_ind: {self.pft_ind}\",\n",
    "                f\"   N cells: {len(self.where)}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def update_pft(self, n_non_crop_pfts):\n",
    "        \"\"\"\n",
    "        You don't know n_non_crop_pfts until after reading in all CFTs, so\n",
    "        this function gets called once that's done in CftList.__init__().\n",
    "        \"\"\"\n",
    "        self.pft_num = n_non_crop_pfts + self.cft_num - 1\n",
    "        self.pft_ind = self.pft_num - 1\n",
    "\n",
    "    def get_where(self, ds):\n",
    "        \"\"\"\n",
    "        Get the indices on the pft dimension corresponding to this CFT\n",
    "        \"\"\"\n",
    "        if self.pft_num is None:\n",
    "            raise RuntimeError(\n",
    "                \"get_where() can't be run until after calling Crop.update_pft()\"\n",
    "            )\n",
    "        pfts1d_itype_veg = ds[\"pfts1d_itype_veg\"]\n",
    "        if \"time\" in pfts1d_itype_veg.dims:\n",
    "            pfts1d_itype_veg = pfts1d_itype_veg.isel(time=0)\n",
    "        self.where = np.where(pfts1d_itype_veg.values == self.pft_num)[0].astype(int)\n",
    "        return self.where\n",
    "\n",
    "\n",
    "class CftList:\n",
    "    def __init__(self, ds, n_pfts, cfts_to_include):\n",
    "        # Get list of all possible CFTs\n",
    "        self.cft_list = []\n",
    "        for i, (key, value) in enumerate(ds.attrs.items()):\n",
    "            if not key.startswith(\"cft_\"):\n",
    "                continue\n",
    "            cft_name = key[4:]\n",
    "            self.cft_list.append(Cft(cft_name, value))\n",
    "\n",
    "        # Ensure that all CFTs in cfts_to_include are present\n",
    "        cfts_in_file = [x.name for x in self.cft_list]\n",
    "        missing_cfts = [x for x in cfts_to_include if x not in cfts_in_file]\n",
    "        if missing_cfts:\n",
    "            msg = (\n",
    "                \"The following are in cfts_to_include but not the dataset: \"\n",
    "                + \", \".join(missing_cfts)\n",
    "            )\n",
    "            raise KeyError(msg)\n",
    "\n",
    "        # Figure out PFT indices\n",
    "        max_cft_num = max([x.cft_num for x in self.cft_list])\n",
    "        n_non_crop_pfts = n_pfts - max_cft_num + 1  # Incl. unvegetated\n",
    "        for cft in self.cft_list:\n",
    "            cft = cft.update_pft(n_non_crop_pfts)\n",
    "\n",
    "        # Only include CFTs we care about\n",
    "        if len(cfts_to_include) != len(np.unique(cfts_to_include)):\n",
    "            raise ValueError(\"Duplicate CFT(s) in cfts_to_include\")\n",
    "        self.cft_list = [x for x in self.cft_list if x.name in cfts_to_include]\n",
    "\n",
    "        # Figure out where the pft index is each CFT\n",
    "        for cft in self.cft_list:\n",
    "            cft.get_where(ds)\n",
    "            if len(cft.where) == 0:\n",
    "                print(\"Warning: No occurrences found of \" + cft.name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.cft_list[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        results = []\n",
    "        for cft in self.cft_list:\n",
    "            results.append(str(cft))\n",
    "        return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "def get_cft_ds(ds, cft):\n",
    "    ds = ds.isel(pft=cft.where)\n",
    "    ds[\"cft\"] = cft.pft_num\n",
    "    ds = ds.set_coords(\"cft\")\n",
    "    for var in ds:\n",
    "        if \"pft\" in ds[var].dims:\n",
    "            ds[var] = ds[var].assign_coords(cft=cft.pft_num)\n",
    "            ds[var] = ds[var].expand_dims(\"cft\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "class Crop:\n",
    "    def __init__(self, name, cft_list, ds):\n",
    "        self.name = name\n",
    "\n",
    "        # Get CFTs included in this crop\n",
    "        self.cft_list = []\n",
    "        for cft in cft_list:\n",
    "            if self.name not in cft.name:\n",
    "                continue\n",
    "            self.cft_list.append(cft)\n",
    "\n",
    "        # Get information for all CFTs in this crop\n",
    "        self.cft_names = []\n",
    "        self.pft_nums = []\n",
    "        self.pft_inds = []\n",
    "        self.where = np.array([], dtype=np.int64)\n",
    "        for cft in self.cft_list:\n",
    "            self.cft_names.append(cft.name)\n",
    "            self.pft_nums.append(cft.pft_num)\n",
    "            self.pft_inds.append(cft.pft_ind)\n",
    "            self.where = np.append(self.where, cft.get_where(ds))\n",
    "        self.where = np.sort(self.where)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}: {', '.join(f'{x.name} ({x.pft_num})' for x in self.cft_list)}\"\n",
    "\n",
    "\n",
    "class CropList:\n",
    "    def __init__(self, crops_to_include, cft_list, ds):\n",
    "        if len(crops_to_include) != len(np.unique(crops_to_include)):\n",
    "            raise ValueError(\"Duplicate crop(s) found in crops_to_include\")\n",
    "        self.crop_list = [Crop(x, cft_list, ds) for x in crops_to_include]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, str):\n",
    "            found = False\n",
    "            for i, crop in enumerate(self.crop_list):\n",
    "                found = crop.name == index\n",
    "                if found:\n",
    "                    break\n",
    "            if not found:\n",
    "                raise KeyError(f\"No crop found matching '{index}'\")\n",
    "            return self.crop_list[i]\n",
    "        return self.crop_list[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        results = []\n",
    "        for crop in self.crop_list:\n",
    "            results.append(str(crop))\n",
    "        return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "def mf_preproc(ds):\n",
    "    ds[\"pfts1d_wtgcell\"] = ds[\"pfts1d_wtgcell\"].expand_dims(\n",
    "        dim=\"time\", axis=0\n",
    "    )  # .assign_coords({\"time\": ds[\"time\"]})\n",
    "    vars_to_drop = [x for x in ds if any(\"lev\" in d for d in ds[x].dims)]\n",
    "    ds = ds.drop_vars(vars_to_drop)\n",
    "    return ds\n",
    "\n",
    "\n",
    "class Case:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        CESM_output_dir,\n",
    "        clm_file_h,\n",
    "        cfts_to_include,\n",
    "        crops_to_include,\n",
    "        start_year,\n",
    "        end_year,\n",
    "    ):\n",
    "        # Get list of all time series files\n",
    "        file_dir = os.path.join(\n",
    "            CESM_output_dir,\n",
    "            name,\n",
    "            \"lnd\",\n",
    "            \"hist\",\n",
    "        )\n",
    "        file_pattern = os.path.join(file_dir, name + \".clm2\" + clm_file_h + \"*.nc\")\n",
    "        file_list = np.sort(glob.glob(file_pattern))\n",
    "        if len(file_list) == 0:\n",
    "            raise FileNotFoundError(\"No files found matching pattern: \" + file_pattern)\n",
    "\n",
    "        # Get list of files to actually include\n",
    "        self.file_list = []\n",
    "        for filename in file_list:\n",
    "            ds = xr.open_dataset(filename)\n",
    "            if (\n",
    "                ds.time.values[0].year <= end_year\n",
    "                and start_year <= ds.time.values[-1].year\n",
    "            ):\n",
    "                self.file_list.append(filename)\n",
    "        if not self.file_list:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No files found with timestamps in {start_year}-{end_year}\"\n",
    "            )\n",
    "\n",
    "        # Read files\n",
    "        # Adding join=\"override\", compat=\"override\", coords=\"minimal\", doesn't fix the graph size\n",
    "        # Adding combine=\"nested\", concat_dim=\"time\" doesn't give time axis to only variables we want\n",
    "        ds = xr.open_mfdataset(\n",
    "            self.file_list,\n",
    "            decode_times=True,\n",
    "            chunks={},\n",
    "            join=\"override\",\n",
    "            compat=\"override\",\n",
    "            coords=\"minimal\",\n",
    "            # combine=\"nested\", concat_dim=\"time\",\n",
    "            data_vars=\"minimal\",\n",
    "            preprocess=mf_preproc,\n",
    "        )\n",
    "\n",
    "        # Get CFT info\n",
    "        self.cft_list = CftList(ds, N_PFTS, cfts_to_include)\n",
    "\n",
    "        # Get crop list\n",
    "        self.crop_list = CropList(crops_to_include, self.cft_list, ds)\n",
    "\n",
    "        # Save CFT dataset\n",
    "        for i, cft in enumerate(self.cft_list):\n",
    "            this_cft_ds = get_cft_ds(ds, cft)\n",
    "\n",
    "            if i == 0:\n",
    "                self.cft_ds = this_cft_ds.copy()\n",
    "                n_expected = self.cft_ds.sizes[\"pft\"]\n",
    "            else:\n",
    "                # Check # of gridcells with this PFT\n",
    "                n_this = this_cft_ds.sizes[\"pft\"]\n",
    "                if n_this != n_expected:\n",
    "                    raise RuntimeError(\n",
    "                        f\"Expected {n_expected} gridcells with {cft.name}; found {n_this}\"\n",
    "                    )\n",
    "                self.cft_ds = xr.concat(\n",
    "                    [self.cft_ds, this_cft_ds],\n",
    "                    dim=\"cft\",\n",
    "                    data_vars=\"minimal\",\n",
    "                    compat=\"override\",\n",
    "                    join=\"override\",\n",
    "                    coords=\"minimal\",\n",
    "                )\n",
    "\n",
    "        # Load\n",
    "        if dev_mode:\n",
    "            if verbose:\n",
    "                start = time()\n",
    "                print(\"Loading...\")\n",
    "            self.cft_ds.load()\n",
    "            if verbose:\n",
    "                end = time()\n",
    "                print(f\"Loading took {int(end - start)} s\")\n",
    "\n",
    "        # Get secondary variables\n",
    "        if verbose:\n",
    "            start = time()\n",
    "            print(\"Getting secondary variables\")\n",
    "        for var in [\"HDATES\", \"SDATES_PERHARV\"]:\n",
    "            self.cft_ds[var] = self.cft_ds[var].where(self.cft_ds[var] >= 0)\n",
    "        self.cft_ds[\"HUIFRAC_PERHARV\"] = c2o.get_huifrac(self.cft_ds)\n",
    "        self.cft_ds[\"GSLEN_PERHARV\"] = c2o.get_gslen(self.cft_ds)\n",
    "        if verbose:\n",
    "            end = time()\n",
    "            print(f\"Secondary variables took {int(end - start)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff581f2e-8178-4ce5-8e04-cc33390d71f8",
   "metadata": {},
   "source": [
    "### 2.2 Import cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35ae8d-dfff-44b0-a854-dfc2b5b030c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "case_list = []\n",
    "for i, case in enumerate(case_name_list):\n",
    "    print(f\"Importing {case}...\")\n",
    "    case_list.append(\n",
    "        Case(\n",
    "            case,\n",
    "            CESM_output_dir,\n",
    "            clm_file_h,\n",
    "            cfts_to_include,\n",
    "            crops_to_include,\n",
    "            start_year,\n",
    "            end_year,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get gridcell area\n",
    "    ds = case_list[-1].cft_ds\n",
    "    area_g = []\n",
    "    for i, lon in enumerate(ds[\"grid1d_lon\"].values):\n",
    "        lat = ds[\"grid1d_lat\"].values[i]\n",
    "        area_g.append(ds[\"area\"].sel(lat=lat, lon=lon))\n",
    "    area_g = np.array(area_g)\n",
    "    area_p = []\n",
    "    for i in ds[\"pfts1d_gi\"].isel(cft=0).values:\n",
    "        area_p.append(area_g[int(i) - 1])\n",
    "    area_p = np.array(area_p)\n",
    "    ds[\"pfts1d_gridcellarea\"] = xr.DataArray(\n",
    "        data=area_p,\n",
    "        coords={\"pft\": ds[\"pft\"].values},\n",
    "        dims=[\"pft\"],\n",
    "    )\n",
    "\n",
    "print(\"Done.\")\n",
    "if verbose:\n",
    "    end = time()\n",
    "    print(f\"Importing took {int(end - start)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5708d0f6-2fee-418d-882c-0202ea88e79c",
   "metadata": {},
   "source": [
    "### 2.3 Import FAOSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d3bb4-4df1-48a2-881c-fc3feab42ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = os.path.join(\n",
    "    obs_data_dir,\n",
    "    \"lnd\",\n",
    "    \"analysis_datasets\",\n",
    "    \"ungridded\",\n",
    "    \"timeseries\",\n",
    "    \"FAOSTAT\",\n",
    "    \"Production_Crops_Livestock_2025-02-25\",\n",
    "    \"norm\",\n",
    ")\n",
    "\n",
    "fao = pd.read_csv(\n",
    "    os.path.join(this_dir, \"Production_Crops_Livestock_E_All_Data_(Normalized).csv\"),\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "fao2 = fao.copy()\n",
    "\n",
    "# Because it's easy to confuse Item vs. Element\n",
    "fao2 = fao2.rename(columns={\"Item\": \"Crop\"}, errors=\"raise\")\n",
    "\n",
    "# Combine \"Maize\" and \"Maize, green\"\n",
    "fao2.Crop = fao2.Crop.replace(\"Maize.*\", \"Maize\", regex=True)\n",
    "fao2 = fao2.groupby(by=[\"Crop\", \"Year\", \"Element\", \"Area\", \"Unit\"], as_index=False).agg(\n",
    "    \"sum\"\n",
    ")\n",
    "\n",
    "# Filter out \"China,\" which includes all Chinas\n",
    "if \"China\" in fao2.Area.values:\n",
    "    fao2 = fao2.query('Area != \"China\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba958fb9-fbea-4211-83fb-eda9ae46a578",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. Yield time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec58a81-335c-4217-8961-f35bc8abc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fao_data_get(fao_all, element, y1, yN, fao_to_clm_dict, cropList_combined_clm):\n",
    "\n",
    "    # Extract element of interest\n",
    "    fao_this = fao_all.copy().query(f\"Element == '{element}'\")\n",
    "    if fao_this.empty:\n",
    "        raise KeyError(f\"No FAOSTAT element found matching {element}\")\n",
    "\n",
    "    # Drop all but columns of interest\n",
    "    fao_this = fao_this[[\"Crop\", \"Year\", \"Element\", \"Area\", \"Unit\", \"Value\"]]\n",
    "\n",
    "    # Extract crops of interest\n",
    "    fao_crops = fao_this.Crop.unique()\n",
    "    fao_crops_from_dict = [crop for crop in fao_to_clm_dict]\n",
    "    missing_crops = [crop for crop in fao_crops_from_dict if crop not in fao_crops]\n",
    "    if missing_crops:\n",
    "        raise KeyError(\n",
    "            f\"Crops missing from FAOSTAT {element}: {'; '.join(missing_crops)}\"\n",
    "        )\n",
    "    fao_this = fao_this[fao_this[\"Crop\"].isin(fao_crops_from_dict)]\n",
    "    if len(fao_this.Crop.unique()) != len(cropList_combined_clm):\n",
    "        raise RuntimeError(\n",
    "            \"Unexpected # crops in FAOSTAT after extracting crops of interest\"\n",
    "        )\n",
    "\n",
    "    # Remove unneeded years\n",
    "    fao_this = fao_this.query(f\"Year >= {y1} & Year <= {yN}\")\n",
    "    if fao_this.empty:\n",
    "        raise KeyError(f\"No FAOSTAT years found in {y1}-{yN}\")\n",
    "\n",
    "    # Rename to match CLM\n",
    "    fao_this[\"Crop\"] = fao_this[\"Crop\"].replace(fao_to_clm_dict)\n",
    "\n",
    "    # Set index\n",
    "    fao_this = fao_this.set_index([\"Crop\", \"Year\", \"Area\"])\n",
    "\n",
    "    return fao_this\n",
    "\n",
    "\n",
    "fao_prod = fao_data_get(\n",
    "    fao2, \"Production\", start_year, end_year, fao_to_clm_dict, crops_to_include\n",
    ")\n",
    "fao_area = fao_data_get(\n",
    "    fao2, \"Area harvested\", start_year, end_year, fao_to_clm_dict, crops_to_include\n",
    ")\n",
    "\n",
    "# Only include where both production and area data are present\n",
    "def drop_a_where_not_in_b(a, b):\n",
    "    return a.drop([i for i in a.index.difference(b.index)])\n",
    "\n",
    "\n",
    "fao_prod = drop_a_where_not_in_b(fao_prod, fao_area)\n",
    "fao_area = drop_a_where_not_in_b(fao_area, fao_prod)\n",
    "if not fao_prod.index.equals(fao_area.index):\n",
    "    raise RuntimeError(\"Mismatch of prod and area indices after trying to align them\")\n",
    "\n",
    "# Don't allow production where no area\n",
    "is_bad = (fao_prod[\"Value\"] > 0) & (fao_area[\"Value\"] == 0)\n",
    "where_bad = np.where(is_bad)[0]\n",
    "bad_prod = fao_prod.iloc[where_bad]\n",
    "bad_area = fao_area.iloc[where_bad]\n",
    "fao_prod = fao_prod[~is_bad]\n",
    "fao_area = fao_area[~is_bad]\n",
    "if not fao_prod.index.equals(fao_area.index):\n",
    "    raise RuntimeError(\n",
    "        \"Mismatch of prod and area indices after disallowing production where no area\"\n",
    "    )\n",
    "\n",
    "# Get yield\n",
    "fao_yield = fao_prod.copy()\n",
    "fao_yield[\"Element\"] = \"Yield\"\n",
    "fao_yield[\"Unit\"] = \"/\".join([fao_prod[\"Unit\"].iloc[0], fao_area[\"Unit\"].iloc[0]])\n",
    "fao_yield[\"Value\"] = fao_prod[\"Value\"] / fao_area[\"Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed96fb-60f2-40e9-b089-700dc0beb984",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    start = time()\n",
    "\n",
    "# Get figure layout info\n",
    "if 5 <= len(crops_to_include) <= 6:\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    height = 10.5\n",
    "    width = 15\n",
    "    hspace = 0.25\n",
    "    wspace = 0.35\n",
    "else:\n",
    "    raise RuntimeError(f\"Specify figure layout for Ncrops=={len(crops_to_include)}\")\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(width, height))\n",
    "\n",
    "fao_yield_world = fao_yield.query(\"Area == 'World'\")\n",
    "\n",
    "for i, crop in enumerate(crops_to_include):\n",
    "    ax = axes.ravel()[i]\n",
    "    plt.sca(ax)\n",
    "\n",
    "    # Plot case data\n",
    "    for case in case_list:\n",
    "        ds = case.cft_ds.sel(cft=case.crop_list[crop].pft_nums)\n",
    "\n",
    "        cft_area = ds[\"pfts1d_gridcellarea\"] * ds[\"pfts1d_wtgcell\"]\n",
    "        if np.any(ds[\"GRAINC_TO_FOOD_PERHARV\"] < 0):\n",
    "            raise ValueError(\"Unexpected negative value(s) in GRAINC_TO_FOOD_PERHARV\")\n",
    "        cft_yield = mci.mark_crops_invalid(\n",
    "            ds,\n",
    "            \"GRAINC_TO_FOOD_PERHARV\",\n",
    "            min_viable_hui=\"isimip3\",\n",
    "            this_pft=crop,\n",
    "            invalid_value=0,\n",
    "        )\n",
    "        cft_prod = cft_yield.sum(dim=\"mxharvests\", skipna=True) * cft_area\n",
    "        cft_prod = ctsm_py.utils.food_grainc_to_harvested_tons_onecrop(cft_prod, crop)\n",
    "        crop_prod_ts = cft_prod.sum(dim=[\"cft\", \"pft\"])\n",
    "        crop_area_ts = cft_area.sum(dim=[\"cft\", \"pft\"])\n",
    "        crop_yield_ts = crop_prod_ts / crop_area_ts\n",
    "\n",
    "        # Plot data\n",
    "        crop_yield_ts *= 1e-6 * 1e4  # Convert g/m2 to tons/ha\n",
    "        crop_yield_ts.name = \"Yield\"\n",
    "        ctsm_units = \"t/ha\"\n",
    "        crop_yield_ts.attrs[\"units\"] = ctsm_units\n",
    "        crop_yield_ts.plot()\n",
    "\n",
    "    # Plot FAOSTAT data\n",
    "    faostat_units = fao_yield_world[\"Unit\"].iloc[0]\n",
    "    if faostat_units != ctsm_units:\n",
    "        raise RuntimeError(\n",
    "            f\"CTSM units ({ctsm_units}) do not match FAOSTAT units ({faostat_units})\"\n",
    "        )\n",
    "    fao_yield_world_thiscrop = fao_yield_world.query(f\"Crop == '{crop}'\")\n",
    "    ax.plot(\n",
    "        crop_yield_ts.time,\n",
    "        fao_yield_world_thiscrop[\"Value\"].values,\n",
    "        \"-k\",\n",
    "    )\n",
    "\n",
    "    # Finish plot\n",
    "    ax.set_title(crop)\n",
    "    ax.legend(case_name_list + [\"FAOSTAT\"])\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=hspace)\n",
    "plt.show()\n",
    "\n",
    "if verbose:\n",
    "    end = time()\n",
    "    print(f\"Time series plots took {int(end - start)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fbf7af-d3bd-4fe0-9c69-d63394da0d6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 4. Yield maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01016ed0-a083-44c8-b34f-8346915f36a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "importlib.reload(ctsm_py.utils)\n",
    "importlib.reload(ctsm_py.crop_secondary_variables)\n",
    "importlib.reload(ctsm_py.mark_crops_invalid)\n",
    "\n",
    "# Get figure layout info\n",
    "N_cases = len(case_name_list)\n",
    "if 2 <= N_cases <= 3:\n",
    "    nrows = 2\n",
    "    ncols = 2\n",
    "    height = 8\n",
    "    width = 15\n",
    "    hspace = 2\n",
    "    wspace = 0\n",
    "else:\n",
    "    raise RuntimeError(f\"Specify figure layout for N_cases=={N_cases}\")\n",
    "\n",
    "if verbose:\n",
    "    start_all = time()\n",
    "for crop in crops_to_include:\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        figsize=(width, height),\n",
    "        subplot_kw={\"projection\": ccrs.PlateCarree()},\n",
    "    )\n",
    "    if verbose:\n",
    "        start = time()\n",
    "        print(crop)\n",
    "    for i, case in enumerate(case_list):\n",
    "        ax = axes.ravel()[i]\n",
    "        plt.sca(ax)\n",
    "        ds = case.cft_ds.sel(cft=case.crop_list[crop].pft_nums)\n",
    "        ds = ds.drop_vars([\"date_written\", \"time_written\"])\n",
    "        # if verbose:\n",
    "        #     print(\"getting mean across time\")\n",
    "        if np.any(ds[\"GRAINC_TO_FOOD_PERHARV\"] < 0):\n",
    "            raise ValueError(\"Unexpected negative value(s) in GRAINC_TO_FOOD_PERHARV\")\n",
    "        cft_yield = ctsm_py.mark_crops_invalid.mark_crops_invalid(\n",
    "            ds,\n",
    "            \"GRAINC_TO_FOOD_PERHARV\",\n",
    "            min_viable_hui=\"isimip3\",\n",
    "            this_pft=crop,\n",
    "            invalid_value=0,\n",
    "        )\n",
    "        cft_yield = cft_yield.sum(dim=\"mxharvests\", skipna=True).mean(dim=\"time\")\n",
    "        # if verbose:\n",
    "        #     print(\"getting CFT-weighted mean\")\n",
    "        ds = ds.mean(dim=\"time\")\n",
    "        ds[\"wtd_yield_across_cfts\"] = cft_yield.weighted(ds[\"pfts1d_wtgcell\"]).mean(\n",
    "            dim=\"cft\"\n",
    "        )\n",
    "        # if verbose:\n",
    "        #     print(\"gridding yields\")\n",
    "        result = ctsm_py.utils.grid_one_variable(ds, \"wtd_yield_across_cfts\")\n",
    "        result = ctsm_py.utils.lon_pm2idl(result)\n",
    "        result = ctsm_py.utils.food_grainc_to_harvested_tons_onecrop(result, crop)\n",
    "\n",
    "        # Cut off Antarctica\n",
    "        antarctica_border = -60\n",
    "        if np.isnan(result.sel(lat=slice(-90, antarctica_border)).max()):\n",
    "            result = result.sel(lat=slice(antarctica_border, 90))\n",
    "\n",
    "        # Plot data\n",
    "        result *= 1e-6 * 1e4  # Convert g/m2 to t/ha\n",
    "        result.name = \"Yield\"\n",
    "        result.attrs[\"units\"] = \"tons / ha\"\n",
    "        # if verbose:\n",
    "        #     print(\"plotting\")\n",
    "        result.plot(\n",
    "            ax=ax,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cbar_kwargs={\"location\": \"bottom\", \"pad\": 0},\n",
    "        )\n",
    "        ax.coastlines(linewidth=0.5)\n",
    "        plt.title(case_name_list[i])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "    fig.suptitle(crop, fontsize=\"x-large\", fontweight=\"bold\")\n",
    "    end = time()\n",
    "    if verbose:\n",
    "        print(f\"{crop} took {end - start} s\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "if verbose:\n",
    "    end_all = time()\n",
    "    print(f\"Maps took {int(end_all - start_all)} s.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cupid-analysis]",
   "language": "python",
   "name": "conda-env-cupid-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
