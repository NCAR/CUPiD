{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add default values for parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add default values for parameters here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## NB1. ROF global monthly, annual, seasonal flows analysis <a id='top'></a>\n",
    "\n",
    "Use \n",
    "\n",
    "1. reach-D19 gauge link ascii\n",
    "2. D19 flow site geopackage\n",
    "3. D19 discharge netCDF\n",
    "4. monthly and yearly flow netCD (history file)\n",
    "\n",
    "[1. Setupt](#setup)\n",
    "\n",
    "[2. Loading data](#load_data)\n",
    "\n",
    "- monthly history files (directory from CESM or postprocessed) from archive. \n",
    "\n",
    "- Reference data is monthly discharge estimates at 922 big river mouths from Dai et al. 2019 data (D19)\n",
    "\n",
    "[3. Large 24 river analysis](#24_large_rivers)\n",
    "\n",
    "- Plotting time seriese (annual, seasonal cycle) and scatter plots at Large 24 selected rivers with D19 referece data\n",
    "\n",
    "[4. Large 50 rivers analysis](#50_large_rivers)\n",
    "\n",
    "- Annual flow summary table at large 50 selected rivers. \n",
    "\n",
    "[5. 922 rivers analysis](#922_rivers)\n",
    "\n",
    "- summary statistics (%bias, rmse, correlation) at all 922 river sites - map and boxplots.\n",
    "\n",
    "[6. basin area vs annual flow](#flow_diagnoisis)\n",
    "\n",
    "Moved this to another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "import scripts.colors as colors\n",
    "from scripts.utility import load_yaml\n",
    "from scripts.utility import no_time_variable\n",
    "\n",
    "rivers_50m = cfeature.NaturalEarthFeature(\"physical\", \"rivers_lake_centerlines\", \"50m\")\n",
    "land = cfeature.LAND\n",
    "\n",
    "print(\"\\nThe Python version: %s.%s.%s\" % sys.version_info[:3])\n",
    "print(xr.__name__, xr.__version__)\n",
    "print(pd.__name__, pd.__version__)\n",
    "print(gpd.__name__, gpd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "## 1. Setup <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# analysis_name = used in figure png and ascii table names\n",
    "# cases = CESM case names and their runoff grid\n",
    "\n",
    "CESM_output_dir = \"\"\n",
    "case_name = \"\"  # case name\n",
    "start_date = \"\"\n",
    "end_date = \"\"\n",
    "\n",
    "analysis_name = \"test\"  # Used for Figure png names\n",
    "grid_name = \"f09_f09_mosart\"\n",
    "\n",
    "serial = False  # use dask LocalCluster\n",
    "lc_kwargs = {}\n",
    "\n",
    "figureSave = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "load config files and some parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = load_yaml(\"./setup/setup.yaml\")\n",
    "\n",
    "domain_dir = setup[\"ancillary_dir\"]  # ancillary directory including such as ROF domain\n",
    "geospatial_dir = setup[\"ancillary_dir\"]  # including shapefiles etc\n",
    "ref_flow_dir = setup[\"ref_flow_dir\"]  # including observed or reference flow data\n",
    "case_meta = setup[\"case_meta\"]  # Case metadata\n",
    "reach_gpkg = setup[\"reach_gpkg\"]  # reach geopackage meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"0010-01\"\n",
    "end_date = \"0015-12\"\n",
    "time_period = slice(f\"{start_date}\", f\"{end_date}\")  # analysis time period\n",
    "nyrs = int(end_date[:4]) - int(start_date[:4]) + 1  # number of years\n",
    "nmons = nyrs * 12  # number of months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### dasks (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Spin up cluster (if running in parallel)\n",
    "client = None\n",
    "if serial:\n",
    "    cluster = LocalCluster(**lc_kwargs)\n",
    "    client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading data <a id='load_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Monthly/annual flow netCDFs\n",
    "- month_data (xr dataset)\n",
    "- year_data (xr dataset)\n",
    "- seas_data (xr dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "reachID = {}\n",
    "month_data = {}\n",
    "year_data = {}\n",
    "seas_data = {}\n",
    "for case, grid in zip([case_name], [grid_name]):\n",
    "    in_dire = os.path.join(CESM_output_dir, case, \"rof/hist\")\n",
    "    model = case_meta[grid][\"model\"]\n",
    "    domain = case_meta[grid][\"domain_nc\"]\n",
    "    # monthly\n",
    "    month_data[case] = (\n",
    "        xr.open_mfdataset(\n",
    "            f\"{in_dire}/{case}.{model}.h*.001?-*.nc\",\n",
    "            data_vars=\"minimal\",\n",
    "            chunks={\"time\": 12},\n",
    "        )\n",
    "        .sel(time=time_period)\n",
    "        .load()\n",
    "    )\n",
    "    # annual\n",
    "    year_data[case] = month_data[case].resample(time=\"YS\").mean(dim=\"time\")\n",
    "\n",
    "    # seasonal (compute here instead of reading for conisistent analysis period)\n",
    "    seas_data[case] = month_data[case].groupby(\"time.month\").mean(\"time\")\n",
    "    vars_no_time = no_time_variable(month_data[case])\n",
    "    seas_data[case][vars_no_time] = seas_data[case][vars_no_time].isel(\n",
    "        month=0, drop=True\n",
    "    )\n",
    "    time = month_data[case][\"time\"]\n",
    "    if domain == \"None\":\n",
    "        reachID[case] = month_data[case][\"reachID\"].values\n",
    "    else:\n",
    "        reachID[case] = xr.open_dataset(f\"{domain_dir}/{domain}\")[\"reachID\"].values\n",
    "    print(f\"Finished loading {case}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Large river ID and name ascii\n",
    "- big_river_50: dictionary {_site_id_:_river name_}\n",
    "- big_river_24: dictionary {_site_id_:_river name_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./setup/large_river_50.txt\", index_col=\"river_name\")\n",
    "big_river_50 = {key: values[\"site_id\"] for key, values in df.iterrows()}\n",
    "big_river_24 = {\n",
    "    key: values[\"site_id\"] for ix, (key, values) in enumerate(df.iterrows()) if ix < 24\n",
    "}  # The first 24 is used for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. reach-D19 gauge link csv\n",
    "- gauge_reach_lnk (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_reach_lnk = {}\n",
    "for case, grid in zip([case_name], [grid_name]):\n",
    "    gauge_reach_lnk[case] = pd.read_csv(\n",
    "        \"%s/D09/D09_925.%s.asc\" % (ref_flow_dir, case_meta[grid][\"network\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 D19 flow site shapefile\n",
    "- gauge_shp (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gauge_shp = gpd.read_file(\n",
    "    os.path.join(ref_flow_dir, \"D09\", \"geospatial\", \"D09_925.gpkg\")\n",
    ")\n",
    "gauge_shp = gauge_shp[gauge_shp[\"id\"] != 9999999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 D19 discharge data\n",
    "- ds_q_obs_mon (xr datasets)\n",
    "- ds_q_obs_yr (xr datasets)\n",
    "- dr_q_obs_seasonal (xr datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# read monthly data\n",
    "ds_q = xr.open_dataset(\n",
    "    \"%s/D09/coastal-stns-Vol-monthly.updated-May2019.mod.nc\" % (ref_flow_dir),\n",
    "    decode_times=False,\n",
    ")\n",
    "ds_q[\"time\"] = xr.cftime_range(\n",
    "    start=\"1900-01-01\", end=\"2018-12-01\", freq=\"MS\", calendar=\"standard\"\n",
    ")\n",
    "\n",
    "# monthly\n",
    "obs_available = True\n",
    "if ds_q[\"time\"].sel(time=time_period).values.size == 0:\n",
    "    obs_available = False\n",
    "    ds_q_obs_mon = xr.DataArray(\n",
    "        data=np.ones((len(time), len(ds_q[\"station\"])), dtype=\"float\") * np.nan,\n",
    "        dims=[\"time\", \"station\"],\n",
    "        coords=dict(\n",
    "            station=ds_q[\"station\"],\n",
    "            time=time,\n",
    "        ),\n",
    "    )\n",
    "else:\n",
    "    ds_q_obs_mon = ds_q[\"FLOW\"].sel(time=time_period)\n",
    "# compute annual flow from monthly\n",
    "ds_q_obs_yr = ds_q_obs_mon.resample(time=\"YE\").mean(dim=\"time\")\n",
    "# compute annual cycle at monthly scale\n",
    "dr_q_obs_seasonal = ds_q_obs_mon.groupby(\"time.month\").mean(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Get indices in observation and simulation for gauge name (processing)\n",
    "- gauge_plot (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gauge_plot = {}\n",
    "for gname, site_id in big_river_50.items():\n",
    "    gauge_plot[gname] = {}\n",
    "    for case in [case_name]:\n",
    "        gauge_ix = [\n",
    "            i for i, gid in enumerate(ds_q.id.values) if gid == site_id\n",
    "        ]  # go through obs Dataset and get index matching to river (gauge) name\n",
    "        gauge_id = ds_q.id.values[gauge_ix][0]  ## guage ID\n",
    "        seg_id = (\n",
    "            gauge_reach_lnk[case]\n",
    "            .loc[gauge_reach_lnk[case][\"gauge_id\"] == gauge_id][\"route_id\"]\n",
    "            .values\n",
    "        )  # matching reach ID in river network\n",
    "        seg_ix = np.argwhere(\n",
    "            reachID[case] == seg_id\n",
    "        )  # matching reach index in river network\n",
    "        if len(seg_ix) == 0:\n",
    "            seg_ix = -999\n",
    "        else:\n",
    "            seg_ix = seg_ix[0]\n",
    "        gauge_plot[gname][case] = [gauge_ix, seg_ix, seg_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "------\n",
    "## 3. Analysis for 24 large rivers <a id='24_large_rivers'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Annual flow series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, axes = plt.subplots(8, 3, figsize=(7.25, 11.5))\n",
    "plt.subplots_adjust(\n",
    "    top=0.975, bottom=0.065, right=0.98, left=0.10, hspace=0.225, wspace=0.250\n",
    ")  # create some space below the plots by increasing the bottom-value\n",
    "\n",
    "for ix, river_name in enumerate(big_river_24.keys()):\n",
    "    row = ix // 3\n",
    "    col = ix % 3\n",
    "    for case, grid in zip([case_name], [grid_name]):\n",
    "        net_idx = gauge_plot[river_name][case][1]\n",
    "        gaug_idx = gauge_plot[river_name][case][0]\n",
    "\n",
    "        q_name = case_meta[grid][\"flow_name\"]\n",
    "        color = case_meta[grid][\"color\"]\n",
    "\n",
    "        if len(net_idx) == 1:\n",
    "            year_data[case][q_name][:, net_idx].plot(\n",
    "                ax=axes[row, col], linestyle=\"-\", c=color, lw=0.75, label=case\n",
    "            )\n",
    "        elif len(net_idx) == 2:  # means 2d grid\n",
    "            year_data[case][q_name][:, net_idx[0], net_idx[1]].plot(\n",
    "                ax=axes[row, col], linestyle=\"-\", c=color, lw=0.75, label=case\n",
    "            )\n",
    "    if obs_available:\n",
    "        ds_q_obs_yr.loc[:, gaug_idx].plot(\n",
    "            ax=axes[row, col],\n",
    "            linestyle=\"None\",\n",
    "            marker=\"o\",\n",
    "            markersize=3,\n",
    "            c=\"k\",\n",
    "            label=\"D17\",\n",
    "        )\n",
    "\n",
    "    axes[row, col].set_title(\"%d %s\" % (ix + 1, river_name), fontsize=8)\n",
    "\n",
    "    axes[row, col].set_xlabel(\"\")\n",
    "    if row < 7:\n",
    "        axes[row, col].set_xticklabels(\"\")\n",
    "    if col == 0:\n",
    "        axes[row, col].set_ylabel(\"Annual flow [m$^3$/s]\", fontsize=8)\n",
    "    else:\n",
    "        axes[row, col].set_ylabel(\"\")\n",
    "    axes[row, col].tick_params(\"both\", labelsize=\"xx-small\")\n",
    "\n",
    "# Legend- make space below the plot-raise bottom. there will be an label below the second last (bottom middle) ax, thanks to the bbox_to_anchor=(x, y) with a negative y-value.\n",
    "axes.flatten()[-2].legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.125, -0.35, 0.75, 0.1),\n",
    "    ncol=5,\n",
    "    fontsize=\"x-small\",\n",
    ")\n",
    "\n",
    "if figureSave:\n",
    "    plt.savefig(f\"./NB1_Fig1_big_river_annual_{analysis_name}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Annual cycle (at monthly step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, axes = plt.subplots(8, 3, figsize=(7.25, 11.5))\n",
    "plt.subplots_adjust(\n",
    "    top=0.975, bottom=0.065, right=0.98, left=0.10, hspace=0.225, wspace=0.250\n",
    ")  # create some space below the plots by increasing the bottom-value\n",
    "\n",
    "for ix, river_name in enumerate(big_river_24.keys()):\n",
    "    row = ix // 3\n",
    "    col = ix % 3\n",
    "    for case, grid in zip([case_name], [grid_name]):\n",
    "\n",
    "        net_idx = gauge_plot[river_name][case][1]\n",
    "        gaug_idx = gauge_plot[river_name][case][0]\n",
    "\n",
    "        q_name = case_meta[grid][\"flow_name\"]\n",
    "        color = case_meta[grid][\"color\"]\n",
    "\n",
    "        if len(net_idx) == 1:  # means vector\n",
    "            seas_data[case][q_name][:, net_idx].plot(\n",
    "                ax=axes[row, col], linestyle=\"-\", c=color, lw=0.75, label=case\n",
    "            )\n",
    "        elif len(net_idx) == 2:  # means 2d grid\n",
    "            seas_data[case][q_name][:, net_idx[0], net_idx[1]].plot(\n",
    "                ax=axes[row, col], linestyle=\"-\", c=color, lw=1.0, label=case\n",
    "            )\n",
    "\n",
    "    if obs_available:\n",
    "        dr_q_obs_seasonal.loc[:, gaug_idx].plot(\n",
    "            ax=axes[row, col],\n",
    "            linestyle=\":\",\n",
    "            lw=0.5,\n",
    "            marker=\"o\",\n",
    "            markersize=2,\n",
    "            c=\"k\",\n",
    "            label=\"D17\",\n",
    "        )\n",
    "\n",
    "    axes[row, col].set_title(\"%d %s\" % (ix + 1, river_name), fontsize=8)\n",
    "    axes[row, col].set_xlabel(\"\")\n",
    "    if row < 7:\n",
    "        axes[row, col].set_xticklabels(\"\")\n",
    "    if col == 0:\n",
    "        axes[row, col].set_ylabel(\"Mon. flow [m$^3$/s]\", fontsize=8)\n",
    "    else:\n",
    "        axes[row, col].set_ylabel(\"\")\n",
    "    axes[row, col].tick_params(\"both\", labelsize=\"xx-small\")\n",
    "\n",
    "# Legend- make space below the plot-raise bottom. there will be an label below the second last (bottom middle) ax, thanks to the bbox_to_anchor=(x, y) with a negative y-value.\n",
    "axes.flatten()[-2].legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.10, -0.30, 0.75, 0.1),\n",
    "    ncol=5,\n",
    "    fontsize=\"x-small\",\n",
    ")\n",
    "\n",
    "if figureSave:\n",
    "    plt.savefig(f\"./NB1_Fig2_big_river_season_{analysis_name}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. scatter plots of monthly flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if obs_available:\n",
    "    # Monthly flow scatter plot\n",
    "    fig, axes = plt.subplots(8, 3, figsize=(7.50, 15.00))\n",
    "    plt.subplots_adjust(\n",
    "        top=0.995, bottom=0.075, right=0.995, left=0.1, wspace=0.25, hspace=0.25\n",
    "    )\n",
    "\n",
    "    for ix, river_name in enumerate(big_river_24.keys()):\n",
    "        row = ix // 3\n",
    "        col = ix % 3\n",
    "        axes[row, col].yaxis.set_major_formatter(FormatStrFormatter(\"%.0f\"))\n",
    "\n",
    "        for jx, (case, grid) in enumerate(zip([case_name], [grid_name])):\n",
    "\n",
    "            net_idx = gauge_plot[river_name][case][1]\n",
    "            gaug_idx = gauge_plot[river_name][case][0]\n",
    "\n",
    "            q_name = case_meta[grid][\"flow_name\"]\n",
    "            color = case_meta[grid][\"color\"]\n",
    "\n",
    "            if len(net_idx) == 1:  # means vector\n",
    "                ds_sim = month_data[case][q_name][:, net_idx].sel(time=time_period)\n",
    "            elif len(net_idx) == 2:  # means 2d grid\n",
    "                ds_sim = (\n",
    "                    month_data[case][q_name][:, net_idx[0], net_idx[1]]\n",
    "                    .sel(time=time_period)\n",
    "                    .squeeze()\n",
    "                )\n",
    "\n",
    "            ds_obs = ds_q_obs_mon.sel(time=time_period).loc[:, gaug_idx]\n",
    "\n",
    "            axes[row, col].plot(\n",
    "                ds_obs, ds_sim, \"o\", c=color, label=case, markersize=4.0, alpha=0.4\n",
    "            )\n",
    "            if jx == 0:\n",
    "                max_val = np.max(ds_obs)\n",
    "                min_val = np.min(ds_obs)\n",
    "            else:\n",
    "                max_val = np.max([np.max(ds_sim), max_val])\n",
    "                min_val = np.min([np.min(ds_sim), min_val])\n",
    "\n",
    "        axes[row, col].plot(\n",
    "            [min_val * 0.98, max_val * 1.02],\n",
    "            [min_val * 0.98, max_val * 1.02],\n",
    "            \":k\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        axes[row, col].annotate(\n",
    "            \"%d %s\" % (ix + 1, river_name),\n",
    "            xy=(0.05, 0.875),\n",
    "            xycoords=\"axes fraction\",\n",
    "            fontsize=8,\n",
    "            bbox=dict(facecolor=\"white\", edgecolor=\"None\", alpha=0.8),\n",
    "        )\n",
    "        if row == 7 and col == 1:\n",
    "            axes[row, col].set_xlabel(\n",
    "                \"Monthly reference discharge [m$^3$/s]\", fontsize=9\n",
    "            )\n",
    "        else:\n",
    "            axes[row, col].set_xlabel(\"\")\n",
    "\n",
    "        if col == 0 and row == 5:\n",
    "            axes[row, col].set_ylabel(\n",
    "                \"Monthly simulated discharge [m$^3$/s]\", fontsize=10\n",
    "            )\n",
    "        else:\n",
    "            axes[row, col].set_ylabel(\"\")\n",
    "        axes[row, col].tick_params(\"both\", labelsize=\"xx-small\")\n",
    "\n",
    "    axes.flatten()[-2].legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.10, -0.40, 0.75, 0.1),\n",
    "        ncol=5,\n",
    "        fontsize=\"x-small\",\n",
    "    )\n",
    "\n",
    "    if figureSave:\n",
    "        plt.savefig(f\"./NB1_Fig3_big_river_month_scatter_{analysis_name}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. scatter plots of annual flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if obs_available:\n",
    "    # annual flow scatter plot\n",
    "    fig, axes = plt.subplots(8, 3, figsize=(7.50, 15.00))\n",
    "    plt.subplots_adjust(\n",
    "        top=0.995, bottom=0.075, right=0.995, left=0.1, wspace=0.25, hspace=0.25\n",
    "    )\n",
    "\n",
    "    for ix, river_name in enumerate(big_river_24.keys()):\n",
    "        row = ix // 3\n",
    "        col = ix % 3\n",
    "        axes[row, col].yaxis.set_major_formatter(FormatStrFormatter(\"%.0f\"))\n",
    "\n",
    "        for jx, (case, grid) in enumerate(zip([case_name], [grid_name])):\n",
    "\n",
    "            net_idx = gauge_plot[river_name][case][1]\n",
    "            gaug_idx = gauge_plot[river_name][case][0]\n",
    "\n",
    "            q_name = case_meta[grid][\"flow_name\"]\n",
    "            color = case_meta[grid][\"color\"]\n",
    "\n",
    "            if len(net_idx) == 1:  # means vector\n",
    "                ds_sim = year_data[case][q_name][:, net_idx].sel(time=time_period)\n",
    "            elif len(net_idx) == 2:  # means 2d grid\n",
    "                ds_sim = year_data[case][q_name][:, net_idx[0], net_idx[1]].sel(\n",
    "                    time=time_period\n",
    "                )\n",
    "\n",
    "            ds_obs = ds_q_obs_yr.sel(time=time_period).loc[:, gaug_idx]\n",
    "\n",
    "            axes[row, col].plot(\n",
    "                ds_obs, ds_sim, \"o\", c=color, label=case, markersize=4.0, alpha=0.4\n",
    "            )\n",
    "            if jx == 0:\n",
    "                max_val = np.max(ds_obs)\n",
    "                min_val = np.min(ds_obs)\n",
    "            else:\n",
    "                max_val = np.max([np.max(ds_sim), max_val])\n",
    "                min_val = np.min([np.min(ds_sim), min_val])\n",
    "\n",
    "        axes[row, col].plot(\n",
    "            [min_val * 0.98, max_val * 1.02],\n",
    "            [min_val * 0.98, max_val * 1.02],\n",
    "            \":k\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        axes[row, col].annotate(\n",
    "            \"%d %s\" % (ix + 1, river_name),\n",
    "            xy=(0.05, 0.875),\n",
    "            xycoords=\"axes fraction\",\n",
    "            fontsize=8,\n",
    "            bbox=dict(facecolor=\"white\", edgecolor=\"None\", alpha=0.8),\n",
    "        )\n",
    "        if row == 7 and col == 1:\n",
    "            axes[row, col].set_xlabel(\n",
    "                \"Monthly reference discharge [m$^3$/s]\", fontsize=9\n",
    "            )\n",
    "        else:\n",
    "            axes[row, col].set_xlabel(\"\")\n",
    "\n",
    "        if col == 0 and row == 5:\n",
    "            axes[row, col].set_ylabel(\n",
    "                \"Monthly simulated discharge [m$^3$/s]\", fontsize=10\n",
    "            )\n",
    "        else:\n",
    "            axes[row, col].set_ylabel(\"\")\n",
    "        axes[row, col].tick_params(\"both\", labelsize=\"xx-small\")\n",
    "\n",
    "    axes.flatten()[-2].legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.10, -0.40, 0.75, 0.1),\n",
    "        ncol=5,\n",
    "        fontsize=\"x-small\",\n",
    "    )\n",
    "\n",
    "    if figureSave:\n",
    "        plt.savefig(f\"./NB1_Fig4_big_river_annual_scatter_{analysis_name}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Anaysis for Large 50 rivers <a id='50_large_rivers'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with open(f\"large50rivers_{analysis_name}.txt\", \"w\") as f:\n",
    "    # some meta\n",
    "    f.write(\"# obs: Dai et al.(2019)\\n\")\n",
    "    f.write(\"# vol: km^3/yr\\n\")\n",
    "    f.write(\"# area: km^2\\n\")\n",
    "\n",
    "    # headers\n",
    "    f.write(\"No,          river_name,\")\n",
    "    f.write(\"{0: >15}_vol,\".format(\"obs\"))\n",
    "    for jx, (case, grid) in enumerate(zip([case_name], [grid_name])):\n",
    "        f.write(\"{0: >15}_vol,\".format(grid))\n",
    "    f.write(\"{0: >15}_area\".format(\"obs\"))\n",
    "    for jx, (case, grid) in enumerate(zip([case_name], [grid_name])):\n",
    "        f.write(\",\")\n",
    "        f.write(\"{0: >15}_area\".format(grid))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    # data for each river\n",
    "    for ix, river_name in enumerate(big_river_50.keys()):\n",
    "\n",
    "        f.write(\"%02d,\" % (ix + 1))\n",
    "        f.write(\"{0: >20}\".format(river_name))\n",
    "\n",
    "        for jx, (case, grid) in enumerate(zip([case_name], [grid_name])):\n",
    "            f.write(\",\")\n",
    "            net_idx = gauge_plot[river_name][case][1]\n",
    "            gaug_idx = gauge_plot[river_name][case][0]\n",
    "\n",
    "            q_name = case_meta[grid][\"flow_name\"]\n",
    "\n",
    "            if len(net_idx) == 1:  # means vector\n",
    "                qsim = (\n",
    "                    np.nanmean(\n",
    "                        year_data[case][q_name][:, net_idx].sel(time=time_period).values\n",
    "                    )\n",
    "                    * 60\n",
    "                    * 60\n",
    "                    * 24\n",
    "                    * 365\n",
    "                    / 10**9\n",
    "                )\n",
    "            elif len(net_idx) == 2:  # means 2d grid\n",
    "                qsim = (\n",
    "                    np.nanmean(\n",
    "                        year_data[case][q_name][:, net_idx[0], net_idx[1]]\n",
    "                        .sel(time=time_period)\n",
    "                        .values\n",
    "                    )\n",
    "                    * 60\n",
    "                    * 60\n",
    "                    * 24\n",
    "                    * 365\n",
    "                    / 10**9\n",
    "                )\n",
    "\n",
    "            if jx == 0:\n",
    "                if ~np.all(np.isnan(ds_q_obs_yr)):\n",
    "                    qobs = (\n",
    "                        np.nanmean(\n",
    "                            ds_q_obs_yr.sel(time=time_period).loc[:, gaug_idx].values\n",
    "                        )\n",
    "                        * 60\n",
    "                        * 60\n",
    "                        * 24\n",
    "                        * 365\n",
    "                        / 10**9\n",
    "                    )\n",
    "                else:\n",
    "                    qobs = np.nan\n",
    "\n",
    "                f.write(\"{:19.1f},\".format(qobs))\n",
    "            f.write(\"{:19.1f}\".format(qsim))\n",
    "\n",
    "        for jx, (case, grid) in enumerate(zip([case_name], [grid_name])):\n",
    "            f.write(\",\")\n",
    "            gaug_idx = gauge_plot[river_name][case][0]\n",
    "\n",
    "            # just get gauge_id from qs_q for now\n",
    "            gauge_id = ds_q[\"id\"].loc[gaug_idx].values[0]\n",
    "            network_area = gauge_reach_lnk[case][\n",
    "                gauge_reach_lnk[case][\"gauge_id\"] == gauge_id\n",
    "            ][\"route_area\"].values[0]\n",
    "\n",
    "            if jx == 0:\n",
    "                area = ds_q[\"area_stn\"].loc[gaug_idx].values[0]\n",
    "                f.write(\"{:20.0f},\".format(area))\n",
    "\n",
    "            f.write(\"{:20.0f}\".format(network_area))\n",
    "\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. scatter plot of annual mean flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if obs_available:\n",
    "\n",
    "    df_yr_vol = pd.read_csv(\n",
    "        f\"./large50rivers_{analysis_name}.txt\",\n",
    "        skiprows=3,\n",
    "        index_col=[\"No\"],\n",
    "        skipinitialspace=True,\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(1, figsize=(5.50, 5.50))\n",
    "    regressor = LinearRegression()\n",
    "    bias_text = \"\"\n",
    "\n",
    "    for jx, (case, grid) in enumerate(zip([case_name], [grid_name])):\n",
    "\n",
    "        # compute linear regression\n",
    "        df_reg = df_yr_vol[[\"obs_vol\", f\"{grid}_vol\"]].dropna()\n",
    "        regressor.fit(df_reg[[\"obs_vol\"]], df_reg[f\"{grid}_vol\"])\n",
    "        y_pred = regressor.predict(df_reg[[\"obs_vol\"]])\n",
    "\n",
    "        # compute bias over 50 sites\n",
    "        diff = (df_yr_vol[f\"{grid}_vol\"] - df_yr_vol[\"obs_vol\"]).mean(\n",
    "            axis=0, skipna=True\n",
    "        )\n",
    "\n",
    "        # color assigned to grid name\n",
    "        color = case_meta[grid][\"color\"]\n",
    "\n",
    "        df_yr_vol.plot(\n",
    "            ax=axes,\n",
    "            kind=\"scatter\",\n",
    "            x=\"obs_vol\",\n",
    "            y=f\"{grid}_vol\",\n",
    "            s=30,\n",
    "            color=color,\n",
    "            alpha=0.6,\n",
    "            label=grid,\n",
    "        )\n",
    "        # plt.plot(df_reg['obs_vol'], y_pred, color=color)\n",
    "        bias_text = bias_text + f\"\\n{grid}: {diff:.1f} \"\n",
    "\n",
    "    plt.text(\n",
    "        0.65, 0.30, \"bias [km3/yr]\", transform=axes.transAxes, verticalalignment=\"top\"\n",
    "    )\n",
    "    plt.text(\n",
    "        0.65, 0.30, f\"{bias_text} \", transform=axes.transAxes, verticalalignment=\"top\"\n",
    "    )\n",
    "\n",
    "    plt.axline((0, 0), slope=1, linestyle=\"--\", color=\"black\")\n",
    "    axes.set_xscale(\"log\")\n",
    "    axes.set_yscale(\"log\")\n",
    "    axes.set_xlabel(\"reference flow\")\n",
    "    axes.set_ylabel(\"Simulated flow\")\n",
    "    axes.set_title(\"River Flow at stations [km^3/yr]\")\n",
    "\n",
    "    if figureSave:\n",
    "        plt.savefig(\n",
    "            f\"./NB1_Fig5_50big_river_annual_flow_scatter_{analysis_name}.png\", dpi=200\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 3. Anaysis for all 922 sites <a id='922_rivers'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Compute metris at all the sites (no plots nor tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if obs_available:\n",
    "    # Merge gauge_reach lnk (dataframe) into gauge shapefile\n",
    "    gauge_shp1 = {}\n",
    "    for case, df in gauge_reach_lnk.items():\n",
    "        # df = df.loc[(df['flag'] == 0)]\n",
    "        df1 = df.drop(columns=[\"riv_name\"])\n",
    "        gauge_shp1[case] = pd.merge(\n",
    "            gauge_shp, df1, how=\"inner\", left_on=\"id\", right_on=\"gauge_id\"\n",
    "        )\n",
    "\n",
    "    # compute %bias, correlation, and RMSE at each site based on monthly\n",
    "    mon_pbias = {}\n",
    "    mon_corr = {}\n",
    "    mon_rmse = {}\n",
    "\n",
    "    for case, grid in zip([case_name], [grid_name]):\n",
    "\n",
    "        bias = np.full(len(gauge_shp1[case]), np.nan, dtype=float)\n",
    "        corr = np.full(len(gauge_shp1[case]), np.nan, dtype=float)\n",
    "        rmse = np.full(len(gauge_shp1[case]), np.nan, dtype=float)\n",
    "\n",
    "        for ix, row in gauge_shp1[case].iterrows():\n",
    "            q_obs = np.full(\n",
    "                nmons, np.nan, dtype=float\n",
    "            )  # dummy q_sim that will be replaced by actual data if exist\n",
    "            q_sim = np.full(\n",
    "                nmons, np.nan, dtype=float\n",
    "            )  # dummy q_sim that will be replaced by actual data if exist\n",
    "\n",
    "            route_id = row[\"route_id\"]\n",
    "            gauge_id = row[\"gauge_id\"]\n",
    "\n",
    "            q_name = case_meta[grid][\"flow_name\"]\n",
    "\n",
    "            gauge_ix = np.argwhere(ds_q.id.values == gauge_id)\n",
    "            if len(gauge_ix) == 1:\n",
    "                gauge_ix = gauge_ix[0]\n",
    "                q_obs = ds_q_obs_mon[:, gauge_ix].squeeze().values\n",
    "\n",
    "            route_ix = np.argwhere(reachID[case] == route_id)\n",
    "            if (\n",
    "                len(route_ix) == 1\n",
    "            ):  # meaning there is flow site in network and simulation exist at this site\n",
    "                route_ix = route_ix[0]\n",
    "                if len(route_ix) == 1:  # means vector\n",
    "                    q_sim = month_data[case][q_name][:, route_ix].squeeze().values\n",
    "                elif len(route_ix) == 2:  # means 2d grid\n",
    "                    q_sim = (\n",
    "                        month_data[case][q_name][:, route_ix[0], route_ix[1]]\n",
    "                        .squeeze()\n",
    "                        .values\n",
    "                    )\n",
    "\n",
    "                # compute %bias, correlation, RMSE\n",
    "                bias[ix] = np.nanmean(q_sim - q_obs) / np.nanmean(q_obs) * 100.0\n",
    "                corr[ix] = np.corrcoef(q_sim, q_obs)[0, 1]\n",
    "                rmse[ix] = np.sqrt(np.mean((q_sim - q_obs) ** 2))\n",
    "\n",
    "        mon_pbias[case] = bias\n",
    "        mon_corr[case] = corr\n",
    "        mon_rmse[case] = rmse\n",
    "\n",
    "        gauge_shp1[case][f\"bias_{grid}\"] = bias\n",
    "        gauge_shp1[case][f\"corr_{grid}\"] = corr\n",
    "        gauge_shp1[case][f\"rmse_{grid}\"] = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Spatial metric map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if obs_available:\n",
    "    # some local plot setups\n",
    "    cbar_kwrgs = {\n",
    "        \"bias\": {\n",
    "            \"shrink\": 0.9,\n",
    "            \"pad\": 0.02,\n",
    "            \"orientation\": \"horizontal\",\n",
    "            \"extend\": \"both\",\n",
    "        },\n",
    "        \"corr\": {\n",
    "            \"shrink\": 0.9,\n",
    "            \"pad\": 0.02,\n",
    "            \"orientation\": \"horizontal\",\n",
    "            \"extend\": \"min\",\n",
    "        },\n",
    "        \"rmse\": {\n",
    "            \"shrink\": 0.9,\n",
    "            \"pad\": 0.02,\n",
    "            \"orientation\": \"horizontal\",\n",
    "            \"extend\": \"max\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    meta = {\n",
    "        \"bias\": {\"name\": \"%bias\", \"vmin\": -100, \"vmax\": 100, \"cm\": colors.cmap11},\n",
    "        \"corr\": {\"name\": \"correlation\", \"vmin\": 0.2, \"vmax\": 1, \"cm\": colors.cmap12},\n",
    "        \"rmse\": {\"name\": \"RMSE\", \"vmin\": 0, \"vmax\": 1000, \"cm\": mpl.cm.turbo},\n",
    "    }\n",
    "\n",
    "    for error_metric in [\"rmse\", \"bias\", \"corr\"]:\n",
    "        for case, grid in zip([case_name], [grid_name]):\n",
    "            fig, ax = plt.subplots(\n",
    "                1, figsize=(7.5, 4.0), subplot_kw={\"projection\": ccrs.PlateCarree()}\n",
    "            )\n",
    "\n",
    "            ax.add_feature(\n",
    "                rivers_50m, facecolor=\"None\", edgecolor=\"b\", lw=0.5, alpha=0.3\n",
    "            )\n",
    "            ax.add_feature(land, facecolor=\"white\", edgecolor=\"grey\")\n",
    "\n",
    "            gauge_shp1[case].plot(\n",
    "                ax=ax,\n",
    "                column=f\"{error_metric}_{grid}\",\n",
    "                markersize=10,\n",
    "                cmap=meta[error_metric][\"cm\"],\n",
    "                vmin=meta[error_metric][\"vmin\"],\n",
    "                vmax=meta[error_metric][\"vmax\"],\n",
    "            )\n",
    "\n",
    "            ax.set_title(\"%s %s\" % (case, meta[error_metric][\"name\"]))\n",
    "\n",
    "            points = ax.collections[-1]\n",
    "            plt.colorbar(points, ax=ax, **cbar_kwrgs[error_metric])\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if figureSave:\n",
    "                plt.savefig(f\"./NB1_Fig6_{error_metric}_{case}_map.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Boxplots of Error metrics (RMSE, %bias, and correlation coefficient)\n",
    "Boxplot distribution is based on metrics sampled at 922 sites.\n",
    "\n",
    "The box extends from the Q1 to Q3 quartile values of the data, with a line at the median (Q2). \n",
    "The whiskers extend from the edges of box to show the range of the data. \n",
    "By default, they extend no more than 1.5 * IQR (IQR = Q3 - Q1) from the edges of the box, ending at the farthest data point within that interval. \n",
    "Outliers are plotted as separate dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if obs_available:\n",
    "    boxprops = {\"linestyle\": \"-\", \"linewidth\": 1.5, \"color\": \"blue\"}\n",
    "    medianprops = {\"linestyle\": \"-\", \"linewidth\": 1.5, \"color\": \"red\"}\n",
    "\n",
    "    for error_metric in [\"rmse\", \"bias\", \"corr\"]:\n",
    "        column_stat = []\n",
    "        gauge_shp_all_case = gauge_shp.copy(deep=True)\n",
    "        for case, grid in zip([case_name], [grid_name]):\n",
    "            gauge_shp_all_case = gauge_shp_all_case.merge(\n",
    "                gauge_shp1[case][[\"id\", f\"{error_metric}_{grid}\"]],\n",
    "                left_on=\"id\",\n",
    "                right_on=\"id\",\n",
    "            )\n",
    "            column_stat.append(f\"{error_metric}_{grid}\")\n",
    "        fig, ax = plt.subplots(1, figsize=(6.5, 4))\n",
    "        gauge_shp_all_case.boxplot(\n",
    "            ax=ax,\n",
    "            column=column_stat,\n",
    "            boxprops=boxprops,\n",
    "            medianprops=medianprops,\n",
    "            sym=\".\",\n",
    "        )\n",
    "\n",
    "        xticklabels = [label[len(error_metric) + 1 :] for label in column_stat]\n",
    "        ax.set_xticklabels(xticklabels)\n",
    "\n",
    "        if error_metric == \"rmse\":\n",
    "            ax.set_ylim([0, 1000])\n",
    "            ax.set_title(\"RMSE [m3/s]\")\n",
    "        elif error_metric == \"bias\":\n",
    "            ax.set_ylim([-150, 250])\n",
    "            ax.set_title(\"%bias [%]\")\n",
    "        elif error_metric == \"corr\":\n",
    "            ax.set_ylim([-0.2, 1])\n",
    "            ax.set_title(\"correlation\")\n",
    "\n",
    "        if figureSave:\n",
    "            plt.savefig(f\"./NB1_Fig7_{error_metric}_boxplot.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupid-analysis",
   "language": "python",
   "name": "cupid-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
